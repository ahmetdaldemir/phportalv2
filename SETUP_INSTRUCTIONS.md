# PHPortal LLM Entegrasyonu - Kurulum TalimatlarÄ±

Bu belge, LLM entegrasyonunun adÄ±m adÄ±m kurulum sÃ¼recini aÃ§Ä±klar.

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Ollama Kurulumu

#### Windows
1. [Ollama](https://ollama.ai/download) sitesinden Windows sÃ¼rÃ¼mÃ¼nÃ¼ indirin
2. Kurulum dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n
3. Kurulum tamamlandÄ±ktan sonra:
```powershell
cd ollama
.\setup-model.ps1
```

#### Linux/Mac
```bash
# Ollama'yÄ± yÃ¼kle
curl -fsSL https://ollama.ai/install.sh | sh

# Model kur
cd ollama
chmod +x setup-model.sh
./setup-model.sh
```

### 2. FastAPI Servisi Kurulumu

#### Windows
```powershell
cd llm_api
.\start-service.ps1
```

#### Linux/Mac
```bash
cd llm_api
chmod +x start-service.sh
./start-service.sh
```

### 3. Laravel YapÄ±landÄ±rmasÄ±

`.env` dosyanÄ±za ekleyin:
```env
LLM_API_URL=http://localhost:8000
LLM_DEFAULT_MODEL=phportal-assistant
LLM_TIMEOUT=300
```

### 4. Test Edin

```bash
# SaÄŸlÄ±k kontrolÃ¼
php artisan tinker
>>> app(App\Services\LlmService::class)->healthCheck()

# Kod analizi
php artisan llm:analyze app/Http/Controllers/HomeController.php

# Proje Ã¶ÄŸrenimi
php artisan llm:learn
```

## ğŸ“‹ DetaylÄ± Kurulum

### AdÄ±m 1: Gereksinimler

- **PHP**: 8.1 veya Ã¼zeri
- **Python**: 3.9 veya Ã¼zeri
- **Ollama**: En son sÃ¼rÃ¼m
- **RAM**: En az 8GB (13B model iÃ§in)
- **Disk**: En az 10GB boÅŸ alan

### AdÄ±m 2: Ollama Model Kurulumu

```bash
# Ollama servisini baÅŸlat (ayrÄ± bir terminal)
ollama serve

# Model kur
cd ollama
# Windows iÃ§in:
.\setup-model.ps1
# Linux/Mac iÃ§in:
./setup-model.sh
```

Model kurulumu tamamlandÄ±ÄŸÄ±nda test edin:
```bash
ollama run phportal-assistant "Merhaba, Laravel hakkÄ±nda bilgin var mÄ±?"
```

### AdÄ±m 3: FastAPI Servisi

```bash
cd llm_api

# Sanal ortam oluÅŸtur
python -m venv venv

# AktifleÅŸtir (Windows)
venv\Scripts\activate
# AktifleÅŸtir (Linux/Mac)
source venv/bin/activate

# Gereksinimleri yÃ¼kle
pip install -r requirements.txt

# Servisi baÅŸlat
python main.py
```

Servis Ã§alÄ±ÅŸÄ±yorsa ÅŸu adresten eriÅŸebilirsiniz:
- API: http://localhost:8000
- DokÃ¼mantasyon: http://localhost:8000/docs

### AdÄ±m 4: Laravel Entegrasyonu

1. **Config dosyasÄ±** zaten gÃ¼ncellenmiÅŸtir (`config/services.php`)

2. **.env dosyasÄ±nÄ±** gÃ¼ncelleyin:
```env
LLM_API_URL=http://localhost:8000
LLM_DEFAULT_MODEL=phportal-assistant
LLM_TIMEOUT=300
```

3. **Route ekleyin** (`routes/api.php` veya `routes/web.php`):
```php
use App\Http\Controllers\LlmController;

Route::prefix('llm')->middleware(['auth'])->group(function () {
    Route::post('/analyze-code', [LlmController::class, 'analyzeCode']);
    Route::post('/fix-bug', [LlmController::class, 'fixBug']);
    Route::post('/learn-project', [LlmController::class, 'learnProject']);
    Route::post('/chat', [LlmController::class, 'chat']);
    Route::get('/health', [LlmController::class, 'healthCheck']);
    Route::get('/models', [LlmController::class, 'listModels']);
});
```

4. **Cache temizle**:
```bash
php artisan config:clear
php artisan cache:clear
```

## ğŸ§ª Test ve DoÄŸrulama

### 1. Servis SaÄŸlÄ±k KontrolÃ¼

```bash
php artisan tinker
```

```php
$llm = app(App\Services\LlmService::class);
$health = $llm->healthCheck();
print_r($health);
```

Beklenen Ã§Ä±ktÄ±:
```
Array
(
    [success] => 1
    [status] => healthy
    [data] => Array
        (
            [status] => healthy
            [ollama_status] => connected
        )
)
```

### 2. Kod Analizi Testi

```bash
php artisan llm:analyze app/Http/Controllers/HomeController.php
```

### 3. Proje Ã–ÄŸrenimi Testi

```bash
php artisan llm:learn
```

### 4. Web API Testi

```bash
curl -X POST http://localhost:8000/health
```

## ğŸ”§ Sorun Giderme

### Sorun: Ollama baÄŸlantÄ± hatasÄ±

**Ã‡Ã¶zÃ¼m**:
```bash
# Ollama servisini baÅŸlat
ollama serve

# FarklÄ± bir terminal'de modeli Ã§alÄ±ÅŸtÄ±r
ollama run phportal-assistant
```

### Sorun: FastAPI baÅŸlamÄ±yor

**Kontroller**:
1. Python sÃ¼rÃ¼mÃ¼nÃ¼ kontrol edin: `python --version` (3.9+)
2. Port 8000 kullanÄ±mda mÄ±?: `netstat -an | findstr 8000`
3. Gereksinimleri yÃ¼kleyin: `pip install -r requirements.txt`

### Sorun: Laravel baÄŸlanamÄ±yor

**Kontroller**:
1. `.env` dosyasÄ± doÄŸru mu?
2. `LLM_API_URL` doÄŸru mu?
3. FastAPI servisi Ã§alÄ±ÅŸÄ±yor mu?: `curl http://localhost:8000/health`

### Sorun: Model yavaÅŸ Ã§alÄ±ÅŸÄ±yor

**Ã‡Ã¶zÃ¼mler**:
1. Daha kÃ¼Ã§Ã¼k model kullanÄ±n (7B yerine 13B)
2. GPU desteÄŸini aktifleÅŸtirin
3. Context boyutunu azaltÄ±n

## ğŸ“š Ek Kaynaklar

- [LLM Integration Guide](./LLM_INTEGRATION_GUIDE.md) - DetaylÄ± kullanÄ±m kÄ±lavuzu
- [Ollama README](./ollama/README.md) - Model yapÄ±landÄ±rmasÄ±
- [FastAPI README](./llm_api/README.md) - API dokÃ¼mantasyonu

## ğŸ¯ Production NotlarÄ±

### GÃ¼venlik

1. **CORS**: Production'da sadece kendi domain'inizi izin verin
2. **Authentication**: API endpoint'lerine auth middleware ekleyin
3. **Rate Limiting**: API Ã§aÄŸrÄ±larÄ±nÄ± sÄ±nÄ±rlayÄ±n

### Performans

1. **Cache**: LLM cevaplarÄ±nÄ± cache'leyin
2. **Queue**: Uzun iÅŸlemleri queue'ya atÄ±n
3. **Load Balancer**: Birden fazla FastAPI instance kullanÄ±n

### Monitoring

1. Log tÃ¼m LLM Ã§aÄŸrÄ±larÄ±nÄ±
2. Response time'larÄ± izleyin
3. Error rate'leri takip edin

## ğŸ¤ Destek

Sorun yaÅŸarsanÄ±z:
1. Loglara bakÄ±n: `storage/logs/laravel.log`
2. FastAPI loglarÄ±nÄ± kontrol edin
3. Ollama loglarÄ±nÄ± inceleyin

## âœ… Kurulum Kontrol Listesi

- [ ] Ollama yÃ¼klendi ve Ã§alÄ±ÅŸÄ±yor
- [ ] phportal-assistant modeli oluÅŸturuldu
- [ ] FastAPI servisi Ã§alÄ±ÅŸÄ±yor (http://localhost:8000)
- [ ] Laravel .env dosyasÄ± yapÄ±landÄ±rÄ±ldÄ±
- [ ] SaÄŸlÄ±k kontrolÃ¼ baÅŸarÄ±lÄ±
- [ ] Artisan komutlarÄ± Ã§alÄ±ÅŸÄ±yor
- [ ] API endpoint'leri eriÅŸilebilir

TÃ¼m adÄ±mlar tamamlandÄ±ysa, sistem kullanÄ±ma hazÄ±r! ğŸ‰

