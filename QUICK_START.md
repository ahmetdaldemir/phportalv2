# LLM Entegrasyonu - HÄ±zlÄ± BaÅŸlangÄ±Ã§

3 adÄ±mda LLM entegrasyonunu baÅŸlatÄ±n!

## 1ï¸âƒ£ Ollama Kur

### Windows
```powershell
# 1. Ä°ndir: https://ollama.ai/download
# 2. Kur ve Ã§alÄ±ÅŸtÄ±r:
cd ollama
.\setup-model.ps1
```

### Linux/Mac
```bash
curl -fsSL https://ollama.ai/install.sh | sh
cd ollama
chmod +x setup-model.sh
./setup-model.sh
```

## 2ï¸âƒ£ FastAPI BaÅŸlat

### Windows
```powershell
cd llm_api
.\start-service.ps1
```

### Linux/Mac
```bash
cd llm_api
chmod +x start-service.sh
./start-service.sh
```

## 3ï¸âƒ£ Laravel YapÄ±landÄ±r

`.env` dosyasÄ±na ekle:
```env
LLM_API_URL=http://localhost:8000
LLM_DEFAULT_MODEL=phportal-assistant
LLM_TIMEOUT=300
```

## âœ… Test Et

```bash
# SaÄŸlÄ±k kontrolÃ¼
curl http://localhost:8000/health

# Kod analizi
php artisan llm:analyze app/Http/Controllers/HomeController.php

# Proje Ã¶ÄŸrenimi
php artisan llm:learn
```

## ðŸŽ¯ KullanÄ±m

### PHP'den
```php
$llm = app(\App\Services\LlmService::class);

// Kod analizi
$result = $llm->analyzeCode($code, $filePath);

// Bug dÃ¼zelt
$result = $llm->fixBug($code, $errorMessage);

// Sohbet et
$result = $llm->chat("Laravel best practice nedir?");
```

### API'den
```bash
curl -X POST http://your-app.com/api/llm/analyze-code \
  -H "Content-Type: application/json" \
  -d '{"code": "<?php ... ?>"}'
```

## ðŸ“– DetaylÄ± DokÃ¼mantasyon

- [Tam Kurulum KÄ±lavuzu](./SETUP_INSTRUCTIONS.md)
- [KullanÄ±m KÄ±lavuzu](./LLM_INTEGRATION_GUIDE.md)
- [Sorun Giderme](./LLM_INTEGRATION_GUIDE.md#sorun-giderme)

## ðŸ†˜ Sorun mu var?

1. Ollama Ã§alÄ±ÅŸÄ±yor mu? â†’ `ollama serve`
2. FastAPI Ã§alÄ±ÅŸÄ±yor mu? â†’ `curl http://localhost:8000/health`
3. Model var mÄ±? â†’ `ollama list`

HÃ¢lÃ¢ sorun varsa [SETUP_INSTRUCTIONS.md](./SETUP_INSTRUCTIONS.md#sorun-giderme) bakÄ±n.

